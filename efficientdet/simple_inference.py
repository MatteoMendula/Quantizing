import torch
torch.hub._validate_not_a_forked_repo=lambda a,b,c: True

# load SSD model pretrained on COCO from Torch Hub
precision = 'fp32'
efficientdet_b0 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0')

# Sample images from the COCO validation set
uris = [
    'http://images.cocodataset.org/val2017/000000397133.jpg',
    'http://images.cocodataset.org/val2017/000000037777.jpg',
    'http://images.cocodataset.org/val2017/000000252219.jpg'
]

# For convenient and comprehensive formatting of input and output of the model, load a set of utility methods.
utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')

# Format images to comply with the network input
inputs = [utils.prepare_input(uri) for uri in uris]
tensor = utils.prepare_tensor(inputs, False)

# The model was trained on COCO dataset, which we need to access in order to
# translate class IDs into object names.
classes_to_labels = utils.get_coco_object_dictionary()

# Next, we run object detection
model = efficientdet_b0.eval().to("cuda")
detections_batch = model(tensor)

print("detections_batch: ", detections_batch)
print("shape of detections_batch: ", detections_batch.shape)

# By default, raw output from SSD network per input image contains 8732 boxes with
# localization and class probability distribution.
# Letâ€™s filter this output to only get reasonable detections (confidence>40%) in a more comprehensive format.
results_per_input = utils.decode_results(detections_batch)
best_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]